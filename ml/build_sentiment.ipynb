{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and merge sentiment data\n",
    "\n",
    "* https://www.kaggle.com/datasets/ankurzing/aspect-based-sentiment-analysis-for-financial-news\n",
    "* https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news\n",
    "* https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_FOLDER = ['..','datasets']\n",
    "SOURCE_DATA = {\n",
    "    'ankurzing_asp':[['kaggle','ankurzing','SEntFiN-v1.1.csv'],'utf-8', None],\n",
    "    'ankurzing_sent':[['kaggle','ankurzing','all-data.csv'],'ansi', None],\n",
    "    'sbhatti':[['kaggle','sbhatti','data.csv'],'utf-8', None]\n",
    "}\n",
    "# Filtered words\n",
    "WORDS:dict = {} # word->WStat\n",
    "TEXTS:list = [] # [ (sentiment, [(word, count))]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WStat:\n",
    "    def __init__(self, score, count) -> None:\n",
    "        self.score = score\n",
    "        self.count = count\n",
    "    def add(self, point, count):\n",
    "        self.score += point\n",
    "        self.count += count\n",
    "    def get_score(self): return self.score\n",
    "    def get_count(self): return self.count\n",
    "# Add words\n",
    "def add_words(point, words:list[str], dst:dict[WStat], txt:list):\n",
    "    wmap = {}\n",
    "    for w in words:\n",
    "        if w in wmap: wmap[w] += 1\n",
    "        else: wmap[w] = 1\n",
    "    for word,count in wmap.items():\n",
    "        if word in dst:\n",
    "            dst[word].add(point,count)\n",
    "        else:\n",
    "            dst[word] = WStat(point,count)\n",
    "    txt.append((point, wmap.items()))\n",
    "# Process 'ankurzing__aspect-based...\n",
    "def prep_ankurzing_asp(df_src:pd.DataFrame, dst:dict, txt:dict):\n",
    "    for _,row in df_src.iterrows():\n",
    "        # get sentiment classification\n",
    "        sentiment = row['Decisions']\n",
    "        sentiment = sentiment[sentiment.find(':')+3]\n",
    "        # score\n",
    "        if sentiment=='p': point = 1\n",
    "        elif sentiment=='n': point = -1\n",
    "        else: point = 0\n",
    "        # get text words\n",
    "        add_words(point, row['Title'].lower().split(), dst, txt)\n",
    "# Process 'ankurzing__sentiment...'\n",
    "def prep_ankurzing_sent(df_src:pd.DataFrame, dst:dict, txt:dict):\n",
    "    for _,row in df_src.iterrows():\n",
    "        # get sentiment classification\n",
    "        sentiment = row[0]\n",
    "        # score\n",
    "        if sentiment=='positive': point = 1\n",
    "        elif sentiment=='negative': point = -1\n",
    "        else: point = 0\n",
    "        # get text words\n",
    "        add_words(point, row[1].lower().split(), dst, txt)\n",
    "# Process 'sbhatti__financial...'\n",
    "def prep_sbhatti(df_src:pd.DataFrame, dst:dict, txt:dict):\n",
    "    for _,row in df_src.iterrows():\n",
    "        # get sentiment classification\n",
    "        sentiment = row['Sentiment']\n",
    "        # score\n",
    "        if sentiment=='positive': point = 1\n",
    "        elif sentiment=='negative': point = -1\n",
    "        else: point = 0\n",
    "        # get text words\n",
    "        add_words(point, row['Sentence'].lower().split(), dst, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Word  Count  Score\n",
      "0  technopolis     29    3.0\n",
      "1        plans    202   -1.0\n",
      "2           to   8192  247.0\n",
      "3      develop     30   15.0\n",
      "4           in   8143  330.0\n",
      "(25780, 3)\n",
      "Word      object\n",
      "Count      int16\n",
      "Score    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "for k in SOURCE_DATA:\n",
    "    item = SOURCE_DATA[k]\n",
    "    if isinstance(item[2],type(None)):\n",
    "        item[2] = pd.read_csv(join(*SOURCE_DATA_FOLDER, *item[0]), encoding=item[1])\n",
    "\n",
    "prep_ankurzing_sent(SOURCE_DATA['ankurzing_sent'][2], WORDS, TEXTS)\n",
    "prep_ankurzing_asp(SOURCE_DATA['ankurzing_asp'][2], WORDS, TEXTS)\n",
    "prep_sbhatti(SOURCE_DATA['sbhatti'][2], WORDS, TEXTS)\n",
    "\n",
    "_words = []\n",
    "_counts = []\n",
    "_scores = []\n",
    "for k in WORDS:\n",
    "    _words.append(k)\n",
    "    _scores.append(WORDS[k].get_score())\n",
    "    _counts.append(WORDS[k].get_count())\n",
    "df_words = pd.DataFrame({\n",
    "    'Word':pd.Series(_words, dtype='str'),\n",
    "    'Count':pd.Series(_counts, dtype='int16'),\n",
    "    'Score':pd.Series(_scores, dtype='float32')\n",
    "})\n",
    "\n",
    "print(df_words.head())\n",
    "print(df_words.shape)\n",
    "print(df_words.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing\n",
      "Row 2100 of 21440.\n",
      "Row 4200 of 21440.\n",
      "Row 6300 of 21440.\n",
      "Row 8400 of 21440.\n",
      "Row 10500 of 21440.\n",
      "Row 12600 of 21440.\n",
      "Row 14700 of 21440.\n",
      "Row 16800 of 21440.\n",
      "Row 18900 of 21440.\n",
      "Row 21000 of 21440.\n",
      "Creating DataFrame.\n",
      "Writing DataFrame to file.\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "words = list(df_words.query('Score < -15 or Score > 15')['Word'])\n",
    "rows = []\n",
    "count = len(TEXTS)\n",
    "current = 0\n",
    "print('Processing')\n",
    "for sentiment,word_tuples in TEXTS:\n",
    "    row = np.zeros(len(words)+1,dtype=np.float32)\n",
    "    row[0] = sentiment\n",
    "    for w,c in word_tuples:\n",
    "        try:\n",
    "            idx = words.index(w)+1\n",
    "            row[idx] = c\n",
    "        except: pass\n",
    "    rows.append(row)\n",
    "    current += 1\n",
    "    if current % 2100 == 0:\n",
    "        print(f'Row {current} of {count}.')\n",
    "\n",
    "# Create feature dataframe\n",
    "print('Creating DataFrame.')\n",
    "df_features = pd.DataFrame(rows, columns=['SCORE']+words)\n",
    "print('Writing DataFrame to file.')\n",
    "df_features.to_csv(join(*SOURCE_DATA_FOLDER,'sentiment.csv'))\n",
    "print('Bye.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
