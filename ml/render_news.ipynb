{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Read in stock analysis posts for a chosen range of dates and compile them to\n",
    "a list of features grouped by the date.\n",
    "\n",
    "Features are the list of words in *features.json* ad the feature values are the\n",
    "word counds for each post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered Rows: 1397891\n",
      "   Unnamed: 0                                              title  \\\n",
      "0         0.0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1         1.0         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2         2.0                      71 Biggest Movers From Friday   \n",
      "3         3.0       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4         4.0  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:00-04:00     A  \n",
      "1  2020-06-03 10:45:00-04:00     A  \n",
      "2  2020-05-26 04:30:00-04:00     A  \n",
      "3  2020-05-22 12:45:00-04:00     A  \n",
      "4  2020-05-22 11:38:00-04:00     A  \n"
     ]
    }
   ],
   "source": [
    "SOURCE_DATA_FOLDER = ['..', 'datasets']\n",
    "SOURCE_DATA = ['kaggle','miguelaenlle','analyst_ratings_processed.csv']\n",
    "# Load the data.\n",
    "df_src = pd.read_csv(join(*SOURCE_DATA_FOLDER,*SOURCE_DATA)).dropna()\n",
    "print('Unfiltered Rows:', df_src.shape[0])\n",
    "print(df_src.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count: 491\n",
      "['to', 'issue', 'crore', 'q2', 'net', 'loss', 'at', 'rs', 'deliver', 'stay', 'now', 'market', 'not', 'will', 'the', 'strong', 'volume', 'growth', 'raises', 'cr', 'bonds', 'ashwani', 'gujral', 'gold', 'on', 'appoints', 'as', 'beats', 'profit', 'sales', 'and', 'watch', 'pharma', 'india', 'through', 'a', 'why', 'stocks', 'us', 'investors', 'mixed', 'amid', 'more', 'oil', 'prices', 'ahead', 'of', 'supply', 'report', 'share', 'steady', 'low', 'thin', 'trade', 'flat', 'in', 'among', 'retail', 'trades', 'china', 'yuan', 'trading', 'bse', 'strategic', 'with', 'bank', 'launches', 'bond', 'firms', 'asia', 'ipo', '1', 'second', 'chief', 'operating', 'for', 'key', 'from', 'q1', 'results', 'may', 'head', 'around', 'after', 'is', 'indian', 'md', 'this', 'business', 'commodity', 'exchange', 'ceo', 'raise', 'pc', 'new', 'today', 'by', 'appointed', 'chairman', 'level', 'global', 'group', 'files', 'engineering', 'k', 'technology', 'director', 'board', 'buying', 'ends', 'little', 'stock', 'million', 'till', 'data', 'stop', 'how', 'deal', 'impact', 'fund', 'quits', 'which', 'sensex', 'should', 'bet', 'top', 'sebi', 'lifts', 'norms', 'against', 'futures', 'companies', 'public', 'asks', 'brokers', 'orders', 'five', 'annual', 'than', 'markets', 'service', 'week', 'all', 'financial', 'joins', 'range', 'sandeep', 'wagle', 'up', 'mitesh', 'thacker', 'ltd', 'seen', 'takes', 'levels', '2014', 'sell', 'rupee', 'short', 'securities', 'picks', 'dollar', 'looks', 'expand', 'rbi', 'sinha', 'what', 'expect', 'policy', 'bets', 'improve', 'mohoni', 'upside', 'launch', 'projects', 'remain', 'quarter', 'mcx', 'other', 'but', 'cut', 'long-term', 'things', 'that', 'sector', 'software', 'asian', 'nsel', 'nse', 'nifty', 'services', 'target', 'pre-market:', 'opening', 'flat;', 'eyed', 'company', 'buy', 'ncdex', 'brent', 'contract', 'its', '2014:', 'mecklai', 'april', 'march', 'well', 'shares', 'ftil', 'operations', 'get', 'posts', 'maker', 'are', 'slump', 'earnings', 'expected', 'it', 'out', 'infosys', 'staff', 'off', 'expects', 'commodities', 'two', 'over', 'hong', 'kong', 'above', 'before', 'jobs', 'fed', 'corporation', 'weak', 'rally', 'we', 'invest', 'case', 'markets:', 'has', 'good', 'ecb', 'issues', 'crude', 'government', 'years', 'chain', 'hit', 'an', 'currency', 'down', 'record', 'points', 'price', 'news', 'mobile', 'auto', 'wall', 'street', 'lower', 'per', 'pick', 'have', 'rise', 'products', 'm', 'dlf', 'attractive', 'f&o', 'space:', 'boost', 'very', 'exit', 'no', 'slips', 'take', 'high', 'fall', 'sat', 'promoter', 'outperform', 'rangebound,', 'below', 'paper', '25', 'employees', 'under', 'strategy', 'our', 'bullish', 'world', 'line', 'court', 'year', 'buys', 'order', 'higher', 'manufacturing', 'networks', 'positive', '-', 'construction', 'plant', 'improved', 'network', 'gain', 'cues', 'term', 'russia', '30', 'city', 'face', 'hits', 'one', 'red', 'position', 'best', 'half', 'acquisition', 'last', 'hopes', 'development', 'due', 'nokia', 'long', 'largest', 'temporary', 'cautious', 'losses', 'estimates', 'period', 'both', 'solutions', 'agreement', 'also', 'during', 'won', 'volatility', '8%', 'been', 'pressure', ':', 'better', 'announced', 'value', 'said', 'like', 'upgrade', 'increased', 'rises', 'surges', 'bags', 'gains', 'upgrades', 'surge', 'revenue', 'jumps', 'climbs', 'buy:', 'further', '$', \"'buy'\", 'jump', 'high;', 'expansion', 'rallies', 'profitability', '20%', 'profit-booking', 'nine', 'double', 'soars', 'highs', '1.5', '52-week', 'potential', 'capacity', 'ab', 'increase', 'robust', 'tyres', 'rose', 'percent', 'months', 'concerns', 'worries', 'presence', 'drag', 'prefer', 'falls', 'dips', 'bounce', 'slide', 'use', 'strengthen', 'poor', 'release', '2011', 'provider', '%', 'project', 'decline', 'raised', 'area', 'aims', 'dip', 'plunge', 'low,', 'slip', 'declines', 'downgrades', 'slumps', 'sluggish', 'bearish', 'subdued', 'fell', '2009', 'plunges', 'negative', 'widens', 'drops', 'tanks', 'drop', '2010', 'warning', 'loses', 'customers', 'significant', 'was', 'machinery', '2005', 'dropped', 'equipment', 'slipped', 'america', 'press', 'able', ',', 'cooperation', 'awarded', 'same', 'leading', 'product', 'mln', 'year-on-year', 'aim', 'respectively', 'narrowed', 'negotiations', 'countries', 'eps', '.', 'according', \"'s\", 'eur', 'corresponding', 'totalled', '(', ')', 'nordic', 'finland', 'signed', 'oyj', 'finnish', '.8', '2006', \"'\", '.1', 'teleste', 'beer', 'hel', 'plc', 'decreased', 'handling', 'were', '``', \"''\", 'personnel', 'grew', 'declined', 'ruukki', 'yit', 'solution', 'received', 'efficiency', '`', 'savings', 'pleased', 'scanfil', 'temporarily', '$aapl']\n"
     ]
    }
   ],
   "source": [
    "# Load features.\n",
    "with open(join(*SOURCE_DATA_FOLDER,'features.json'),'rb') as f:\n",
    "    features = json.load(f)\n",
    "print('Feature count:', len(features))\n",
    "print(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data\n",
    "\n",
    "### Filter out choser date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2020-01', '2020-02', '2020-03') has 59852 rows.\n"
     ]
    }
   ],
   "source": [
    "MONTHS = ('2020-01','2020-02','2020-03')\n",
    "\n",
    "bool_filter = df_src['date'].str.startswith(MONTHS)\n",
    "df_filtered = df_src[bool_filter]\n",
    "print(f'{MONTHS} has {df_filtered.shape[0]} rows.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date_title = pd.concat([df_filtered['date'].str[:10],df_filtered['title']], axis=1)\n",
    "df_by_date = df_date_title.groupby(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_BY_DATE = {}\n",
    "\n",
    "for date, group in df_by_date:\n",
    "    words = []\n",
    "    for sentence in list(group['title']):\n",
    "        words.extend(sentence.lower().split())\n",
    "    WORDS_BY_DATE[date] = words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature samples\n",
    "\n",
    "Create samples from list of word lists by counting words and setting the\n",
    "corresponding feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2020-01-01 to 2020-03-31 (91 days)\n"
     ]
    }
   ],
   "source": [
    "DATE_FEATURES = []\n",
    "current = 0\n",
    "total = df_filtered.shape[0]\n",
    "for date,words in WORDS_BY_DATE.items():\n",
    "    # get word histogram for date\n",
    "    wmap = {}\n",
    "    for w in words:\n",
    "        if w in wmap: wmap[w] += 1\n",
    "        else: wmap[w] = 1\n",
    "    # feature list\n",
    "    row = [0]*len(features)\n",
    "    #row = np.zeros(len(features),dtype=np.float32)\n",
    "    for word,word_count in wmap.items():\n",
    "        try:\n",
    "            idx = features.index(word)\n",
    "            row[idx] = word_count\n",
    "        except: pass\n",
    "    DATE_FEATURES.append([date]+row)\n",
    "    current += 1\n",
    "    if current % 5000 == 0:\n",
    "        print(f'Row {current} of {total}.')\n",
    "\n",
    "dates = list(WORDS_BY_DATE.keys())\n",
    "start_date = dates[0]\n",
    "end_date = dates[-1]\n",
    "\n",
    "print('Date range:',start_date,'to',end_date,f'({len(dates)} days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrame.\n",
      "Writing DataFrame to file.\n",
      "Bye.\n"
     ]
    }
   ],
   "source": [
    "# Create feature dataframe\n",
    "print('Creating DataFrame.')\n",
    "df_features = pd.DataFrame(DATE_FEATURES, columns=['DATE']+features)\n",
    "print('Writing DataFrame to file.')\n",
    "df_features.to_csv(join(*SOURCE_DATA_FOLDER,'news_features.csv'))\n",
    "print('Bye.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
